{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "mlrepo = anndata.read_h5ad(\"../data/mlrepo6.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8066a8122d442839c0882400ad76347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>embedding</th>\n",
       "      <th>fold</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ravel_black-hispanic</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ravel_black-hispanic</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ravel_black-hispanic</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ravel_black-hispanic</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ravel_black-hispanic</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>turnbaugh_obese-lean-all</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>turnbaugh_obese-lean-all</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.663265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>turnbaugh_obese-lean-all</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>turnbaugh_obese-lean-all</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>turnbaugh_obese-lean-all</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>auc</td>\n",
       "      <td>0.459184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          task embedding  fold    metric     score\n",
       "0         ravel_black-hispanic       raw     0  accuracy  0.575000\n",
       "1         ravel_black-hispanic       raw     0        f1  0.564103\n",
       "2         ravel_black-hispanic       raw     0       auc  0.593985\n",
       "3         ravel_black-hispanic       raw     1  accuracy  0.600000\n",
       "4         ravel_black-hispanic       raw     1        f1  0.555556\n",
       "...                        ...       ...   ...       ...       ...\n",
       "1705  turnbaugh_obese-lean-all    random     3        f1  0.857143\n",
       "1706  turnbaugh_obese-lean-all    random     3       auc  0.663265\n",
       "1707  turnbaugh_obese-lean-all    random     4  accuracy  0.750000\n",
       "1708  turnbaugh_obese-lean-all    random     4        f1  0.857143\n",
       "1709  turnbaugh_obese-lean-all    random     4       auc  0.459184\n",
       "\n",
       "[1710 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Configuration\n",
    "TASK = \"classification\"  # or \"regression\"\n",
    "# TASK = \"regression\"\n",
    "MODEL = RandomForestRegressor if TASK == \"regression\" else RandomForestClassifier\n",
    "FOLDS = 5\n",
    "\n",
    "# Dataset and embedding configuration\n",
    "DATASETS = mlrepo.obs.columns.drop(\"dataset\")\n",
    "REGRESSION_DATASETS = [\n",
    "    \"ravel_nugent-score\",\n",
    "    \"ravel_ph\",\n",
    "    \"gevers_pcdai-ileum\",\n",
    "    \"gevers_pcdai-rectum\",\n",
    "    \"yatsunenko_baby-age\",\n",
    "]\n",
    "CLASSIFICATION_DATASETS = [d for d in DATASETS if d not in REGRESSION_DATASETS]\n",
    "DATASETS_FINAL = REGRESSION_DATASETS if TASK == \"regression\" else CLASSIFICATION_DATASETS\n",
    "\n",
    "EMBEDDINGS = [\n",
    "    \"raw\",\n",
    "    # \"H2\",\n",
    "    # \"H4\",\n",
    "    # \"H8\",\n",
    "    # \"H16\",\n",
    "    # \"H32\",\n",
    "    # \"H64\",\n",
    "    \"H128\",\n",
    "    # \"E2\",\n",
    "    # \"E4\",\n",
    "    # \"E8\",\n",
    "    # \"E16\",\n",
    "    # \"E32\",\n",
    "    # \"E64\",\n",
    "    \"E128\",\n",
    "    \"PCA128\",\n",
    "    \"dnabert-s\",\n",
    "    \"random\",\n",
    "]\n",
    "METRICS = [\"accuracy\", \"f1\", \"auc\"] if TASK == \"classification\" else [\"r2\", \"mae\", \"rmse\"]\n",
    "\n",
    "\n",
    "def get_embedding(mlrepo_filtered, embedding_name):\n",
    "    \"\"\"Get embedding data and product manifold\"\"\"\n",
    "    if embedding_name == \"raw\":\n",
    "        X = mlrepo_filtered.X\n",
    "    elif embedding_name == \"random\":\n",
    "        X = np.random.randn(mlrepo_filtered.X.shape[0], 128)\n",
    "    else:\n",
    "        X = mlrepo_filtered.obsm[embedding_name]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def calculate_score(y_true, y_pred, metric):\n",
    "    \"\"\"Calculate the specified evaluation metric\"\"\"\n",
    "    if metric in [\"accuracy\", \"f1\"]:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    elif metric == \"auc\":\n",
    "        y_pred = y_pred[:, 1]\n",
    "\n",
    "    if metric == \"accuracy\":\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif metric == \"f1\":\n",
    "        return f1_score(y_true, y_pred)\n",
    "    elif metric == \"auc\":\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    elif metric == \"r2\":\n",
    "        return r2_score(y_true, y_pred)\n",
    "    elif metric == \"mae\":\n",
    "        return mean_absolute_error(y_true, y_pred)\n",
    "    elif metric == \"rmse\":\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # elif metric == \"percent_rmse\":\n",
    "    # return (np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"raw_values\")) / y_true).mean()\n",
    "\n",
    "\n",
    "scores = pd.DataFrame(columns=[\"task\", \"embedding\", \"fold\", \"metric\", \"score\"])\n",
    "\n",
    "# Calculate total iterations and initialize progress bar\n",
    "total_iterations = len(DATASETS_FINAL) * len(EMBEDDINGS) * FOLDS * len(METRICS)\n",
    "my_tqdm = tqdm(total=total_iterations)\n",
    "\n",
    "for task in DATASETS_FINAL:\n",
    "    # Filter mlrepo; drop empty columns\n",
    "    mlrepo_filtered = mlrepo[mlrepo.obs[task].notna()]\n",
    "    mlrepo_filtered = mlrepo_filtered[:, (mlrepo_filtered.X > 0).sum(axis=0) > 0]\n",
    "\n",
    "    # Get target values\n",
    "    y = np.array(mlrepo_filtered.obs[task].values)\n",
    "    if TASK == \"classification\":\n",
    "        y = OrdinalEncoder().fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    else:\n",
    "        y = y.flatten()\n",
    "\n",
    "    # Set up cross-validation\n",
    "    if TASK == \"classification\":\n",
    "        kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create folds once to ensure consistency\n",
    "    folds = list(kf.split(np.zeros(len(y)), y))\n",
    "\n",
    "    for embedding in EMBEDDINGS:\n",
    "        # Get embedding data\n",
    "        X = get_embedding(mlrepo_filtered, embedding)\n",
    "\n",
    "        for fold_idx, (train_index, test_index) in enumerate(folds):\n",
    "            # Convert data to tensors\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Train model\n",
    "            model = MODEL()\n",
    "            model.fit(X_train, y_train)\n",
    "            if TASK == \"classification\":\n",
    "                y_out = model.predict_proba(X_test)  # Need this for ROC-AUC calculations\n",
    "            else:\n",
    "                y_out = model.predict(X_test)\n",
    "\n",
    "            # Calculate and store scores for each metric\n",
    "            for metric in METRICS:\n",
    "                score = calculate_score(y_test, y_out, metric)\n",
    "                scores.loc[len(scores)] = [task, embedding, fold_idx, metric, score]\n",
    "\n",
    "                # Update progress bar\n",
    "                my_tqdm.update(1)\n",
    "                my_tqdm.set_postfix(task=task, embedding=embedding, fold=fold_idx, metric=metric, score=score)\n",
    "\n",
    "        # Save checkpoint after each embedding\n",
    "        task_scores = scores[scores[\"task\"] == task]\n",
    "\n",
    "my_tqdm.close()\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(f\"../results/benchmark_scores_sklearn_rf_None_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2f51_row0_col0, #T_f2f51_row0_col4, #T_f2f51_row1_col0, #T_f2f51_row1_col1, #T_f2f51_row1_col2, #T_f2f51_row1_col3, #T_f2f51_row1_col4, #T_f2f51_row2_col0, #T_f2f51_row3_col0, #T_f2f51_row4_col0, #T_f2f51_row5_col0, #T_f2f51_row6_col0, #T_f2f51_row6_col1, #T_f2f51_row6_col2, #T_f2f51_row6_col3, #T_f2f51_row7_col0, #T_f2f51_row8_col0, #T_f2f51_row8_col1, #T_f2f51_row8_col2, #T_f2f51_row8_col3, #T_f2f51_row8_col4, #T_f2f51_row9_col0, #T_f2f51_row10_col0, #T_f2f51_row11_col1, #T_f2f51_row12_col0, #T_f2f51_row13_col0, #T_f2f51_row14_col0, #T_f2f51_row15_col0, #T_f2f51_row16_col0, #T_f2f51_row17_col0, #T_f2f51_row18_col0, #T_f2f51_row18_col3 {\n",
       "  background-color: darkgreen;\n",
       "}\n",
       "#T_f2f51_row2_col4, #T_f2f51_row3_col4, #T_f2f51_row3_col5, #T_f2f51_row4_col3, #T_f2f51_row5_col3, #T_f2f51_row7_col1, #T_f2f51_row9_col2, #T_f2f51_row10_col2, #T_f2f51_row11_col2, #T_f2f51_row12_col2, #T_f2f51_row13_col1, #T_f2f51_row14_col1, #T_f2f51_row15_col4, #T_f2f51_row16_col3, #T_f2f51_row17_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2f51\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >embedding</th>\n",
       "      <th id=\"T_f2f51_level0_col0\" class=\"col_heading level0 col0\" >raw</th>\n",
       "      <th id=\"T_f2f51_level0_col1\" class=\"col_heading level0 col1\" >H128</th>\n",
       "      <th id=\"T_f2f51_level0_col2\" class=\"col_heading level0 col2\" >E128</th>\n",
       "      <th id=\"T_f2f51_level0_col3\" class=\"col_heading level0 col3\" >PCA128</th>\n",
       "      <th id=\"T_f2f51_level0_col4\" class=\"col_heading level0 col4\" >dnabert-s</th>\n",
       "      <th id=\"T_f2f51_level0_col5\" class=\"col_heading level0 col5\" >random</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row0\" class=\"row_heading level0 row0\" >cho_control-ct-cecal</th>\n",
       "      <td id=\"T_f2f51_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row0_col1\" class=\"data row0 col1\" >0.850000</td>\n",
       "      <td id=\"T_f2f51_row0_col2\" class=\"data row0 col2\" >0.875000</td>\n",
       "      <td id=\"T_f2f51_row0_col3\" class=\"data row0 col3\" >0.900000</td>\n",
       "      <td id=\"T_f2f51_row0_col4\" class=\"data row0 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row0_col5\" class=\"data row0 col5\" >0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row1\" class=\"row_heading level0 row1\" >cho_control-ct-fecal</th>\n",
       "      <td id=\"T_f2f51_row1_col0\" class=\"data row1 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row1_col4\" class=\"data row1 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row1_col5\" class=\"data row1 col5\" >0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row2\" class=\"row_heading level0 row2\" >cho_penicillin-vancomycin-cecal</th>\n",
       "      <td id=\"T_f2f51_row2_col0\" class=\"data row2 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row2_col1\" class=\"data row2 col1\" >0.900000</td>\n",
       "      <td id=\"T_f2f51_row2_col2\" class=\"data row2 col2\" >0.900000</td>\n",
       "      <td id=\"T_f2f51_row2_col3\" class=\"data row2 col3\" >0.800000</td>\n",
       "      <td id=\"T_f2f51_row2_col4\" class=\"data row2 col4\" >0.950000</td>\n",
       "      <td id=\"T_f2f51_row2_col5\" class=\"data row2 col5\" >0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row3\" class=\"row_heading level0 row3\" >cho_penicillin-vancomycin-fecal</th>\n",
       "      <td id=\"T_f2f51_row3_col0\" class=\"data row3 col0\" >0.950000</td>\n",
       "      <td id=\"T_f2f51_row3_col1\" class=\"data row3 col1\" >0.800000</td>\n",
       "      <td id=\"T_f2f51_row3_col2\" class=\"data row3 col2\" >0.750000</td>\n",
       "      <td id=\"T_f2f51_row3_col3\" class=\"data row3 col3\" >0.450000</td>\n",
       "      <td id=\"T_f2f51_row3_col4\" class=\"data row3 col4\" >0.900000</td>\n",
       "      <td id=\"T_f2f51_row3_col5\" class=\"data row3 col5\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row4\" class=\"row_heading level0 row4\" >gevers_ileum</th>\n",
       "      <td id=\"T_f2f51_row4_col0\" class=\"data row4 col0\" >0.820521</td>\n",
       "      <td id=\"T_f2f51_row4_col1\" class=\"data row4 col1\" >0.768934</td>\n",
       "      <td id=\"T_f2f51_row4_col2\" class=\"data row4 col2\" >0.770457</td>\n",
       "      <td id=\"T_f2f51_row4_col3\" class=\"data row4 col3\" >0.770897</td>\n",
       "      <td id=\"T_f2f51_row4_col4\" class=\"data row4 col4\" >0.748774</td>\n",
       "      <td id=\"T_f2f51_row4_col5\" class=\"data row4 col5\" >0.422260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row5\" class=\"row_heading level0 row5\" >gevers_rectum</th>\n",
       "      <td id=\"T_f2f51_row5_col0\" class=\"data row5 col0\" >0.848114</td>\n",
       "      <td id=\"T_f2f51_row5_col1\" class=\"data row5 col1\" >0.759945</td>\n",
       "      <td id=\"T_f2f51_row5_col2\" class=\"data row5 col2\" >0.786580</td>\n",
       "      <td id=\"T_f2f51_row5_col3\" class=\"data row5 col3\" >0.794690</td>\n",
       "      <td id=\"T_f2f51_row5_col4\" class=\"data row5 col4\" >0.738280</td>\n",
       "      <td id=\"T_f2f51_row5_col5\" class=\"data row5 col5\" >0.527617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row6\" class=\"row_heading level0 row6\" >hmp_gastro-oral</th>\n",
       "      <td id=\"T_f2f51_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row6_col2\" class=\"data row6 col2\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row6_col3\" class=\"data row6 col3\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row6_col4\" class=\"data row6 col4\" >0.999976</td>\n",
       "      <td id=\"T_f2f51_row6_col5\" class=\"data row6 col5\" >0.465403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row7\" class=\"row_heading level0 row7\" >hmp_sex</th>\n",
       "      <td id=\"T_f2f51_row7_col0\" class=\"data row7 col0\" >0.657149</td>\n",
       "      <td id=\"T_f2f51_row7_col1\" class=\"data row7 col1\" >0.650425</td>\n",
       "      <td id=\"T_f2f51_row7_col2\" class=\"data row7 col2\" >0.595384</td>\n",
       "      <td id=\"T_f2f51_row7_col3\" class=\"data row7 col3\" >0.596533</td>\n",
       "      <td id=\"T_f2f51_row7_col4\" class=\"data row7 col4\" >0.577343</td>\n",
       "      <td id=\"T_f2f51_row7_col5\" class=\"data row7 col5\" >0.486802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row8\" class=\"row_heading level0 row8\" >hmp_stool-tongue-paired</th>\n",
       "      <td id=\"T_f2f51_row8_col0\" class=\"data row8 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row8_col1\" class=\"data row8 col1\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row8_col2\" class=\"data row8 col2\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row8_col3\" class=\"data row8 col3\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row8_col4\" class=\"data row8 col4\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row8_col5\" class=\"data row8 col5\" >0.522797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row9\" class=\"row_heading level0 row9\" >hmp_sub-supragingivalplaque-paired</th>\n",
       "      <td id=\"T_f2f51_row9_col0\" class=\"data row9 col0\" >0.837913</td>\n",
       "      <td id=\"T_f2f51_row9_col1\" class=\"data row9 col1\" >0.745117</td>\n",
       "      <td id=\"T_f2f51_row9_col2\" class=\"data row9 col2\" >0.762298</td>\n",
       "      <td id=\"T_f2f51_row9_col3\" class=\"data row9 col3\" >0.759496</td>\n",
       "      <td id=\"T_f2f51_row9_col4\" class=\"data row9 col4\" >0.760766</td>\n",
       "      <td id=\"T_f2f51_row9_col5\" class=\"data row9 col5\" >0.496426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row10\" class=\"row_heading level0 row10\" >ravel_black-hispanic</th>\n",
       "      <td id=\"T_f2f51_row10_col0\" class=\"data row10 col0\" >0.642444</td>\n",
       "      <td id=\"T_f2f51_row10_col1\" class=\"data row10 col1\" >0.535401</td>\n",
       "      <td id=\"T_f2f51_row10_col2\" class=\"data row10 col2\" >0.546805</td>\n",
       "      <td id=\"T_f2f51_row10_col3\" class=\"data row10 col3\" >0.522293</td>\n",
       "      <td id=\"T_f2f51_row10_col4\" class=\"data row10 col4\" >0.523697</td>\n",
       "      <td id=\"T_f2f51_row10_col5\" class=\"data row10 col5\" >0.470401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row11\" class=\"row_heading level0 row11\" >ravel_nugent-category</th>\n",
       "      <td id=\"T_f2f51_row11_col0\" class=\"data row11 col0\" >0.980768</td>\n",
       "      <td id=\"T_f2f51_row11_col1\" class=\"data row11 col1\" >0.980983</td>\n",
       "      <td id=\"T_f2f51_row11_col2\" class=\"data row11 col2\" >0.980934</td>\n",
       "      <td id=\"T_f2f51_row11_col3\" class=\"data row11 col3\" >0.972218</td>\n",
       "      <td id=\"T_f2f51_row11_col4\" class=\"data row11 col4\" >0.975934</td>\n",
       "      <td id=\"T_f2f51_row11_col5\" class=\"data row11 col5\" >0.479082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row12\" class=\"row_heading level0 row12\" >ravel_white-black</th>\n",
       "      <td id=\"T_f2f51_row12_col0\" class=\"data row12 col0\" >0.666074</td>\n",
       "      <td id=\"T_f2f51_row12_col1\" class=\"data row12 col1\" >0.628281</td>\n",
       "      <td id=\"T_f2f51_row12_col2\" class=\"data row12 col2\" >0.641294</td>\n",
       "      <td id=\"T_f2f51_row12_col3\" class=\"data row12 col3\" >0.602746</td>\n",
       "      <td id=\"T_f2f51_row12_col4\" class=\"data row12 col4\" >0.635551</td>\n",
       "      <td id=\"T_f2f51_row12_col5\" class=\"data row12 col5\" >0.565654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row13\" class=\"row_heading level0 row13\" >sokol_healthy-cd</th>\n",
       "      <td id=\"T_f2f51_row13_col0\" class=\"data row13 col0\" >0.866414</td>\n",
       "      <td id=\"T_f2f51_row13_col1\" class=\"data row13 col1\" >0.708081</td>\n",
       "      <td id=\"T_f2f51_row13_col2\" class=\"data row13 col2\" >0.655556</td>\n",
       "      <td id=\"T_f2f51_row13_col3\" class=\"data row13 col3\" >0.616162</td>\n",
       "      <td id=\"T_f2f51_row13_col4\" class=\"data row13 col4\" >0.673485</td>\n",
       "      <td id=\"T_f2f51_row13_col5\" class=\"data row13 col5\" >0.405556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row14\" class=\"row_heading level0 row14\" >sokol_healthy-uc</th>\n",
       "      <td id=\"T_f2f51_row14_col0\" class=\"data row14 col0\" >0.869907</td>\n",
       "      <td id=\"T_f2f51_row14_col1\" class=\"data row14 col1\" >0.703704</td>\n",
       "      <td id=\"T_f2f51_row14_col2\" class=\"data row14 col2\" >0.681481</td>\n",
       "      <td id=\"T_f2f51_row14_col3\" class=\"data row14 col3\" >0.632407</td>\n",
       "      <td id=\"T_f2f51_row14_col4\" class=\"data row14 col4\" >0.702778</td>\n",
       "      <td id=\"T_f2f51_row14_col5\" class=\"data row14 col5\" >0.631019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row15\" class=\"row_heading level0 row15\" >turnbaugh_obese-lean-all</th>\n",
       "      <td id=\"T_f2f51_row15_col0\" class=\"data row15 col0\" >0.785529</td>\n",
       "      <td id=\"T_f2f51_row15_col1\" class=\"data row15 col1\" >0.620192</td>\n",
       "      <td id=\"T_f2f51_row15_col2\" class=\"data row15 col2\" >0.620284</td>\n",
       "      <td id=\"T_f2f51_row15_col3\" class=\"data row15 col3\" >0.622356</td>\n",
       "      <td id=\"T_f2f51_row15_col4\" class=\"data row15 col4\" >0.631014</td>\n",
       "      <td id=\"T_f2f51_row15_col5\" class=\"data row15 col5\" >0.630303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row16\" class=\"row_heading level0 row16\" >yatsunenko_malawi-venezuela</th>\n",
       "      <td id=\"T_f2f51_row16_col0\" class=\"data row16 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row16_col1\" class=\"data row16 col1\" >0.778571</td>\n",
       "      <td id=\"T_f2f51_row16_col2\" class=\"data row16 col2\" >0.800476</td>\n",
       "      <td id=\"T_f2f51_row16_col3\" class=\"data row16 col3\" >0.874048</td>\n",
       "      <td id=\"T_f2f51_row16_col4\" class=\"data row16 col4\" >0.867143</td>\n",
       "      <td id=\"T_f2f51_row16_col5\" class=\"data row16 col5\" >0.343929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row17\" class=\"row_heading level0 row17\" >yatsunenko_sex</th>\n",
       "      <td id=\"T_f2f51_row17_col0\" class=\"data row17 col0\" >0.611424</td>\n",
       "      <td id=\"T_f2f51_row17_col1\" class=\"data row17 col1\" >0.525418</td>\n",
       "      <td id=\"T_f2f51_row17_col2\" class=\"data row17 col2\" >0.455007</td>\n",
       "      <td id=\"T_f2f51_row17_col3\" class=\"data row17 col3\" >0.427094</td>\n",
       "      <td id=\"T_f2f51_row17_col4\" class=\"data row17 col4\" >0.455258</td>\n",
       "      <td id=\"T_f2f51_row17_col5\" class=\"data row17 col5\" >0.412333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2f51_level0_row18\" class=\"row_heading level0 row18\" >yatsunenko_usa-malawi</th>\n",
       "      <td id=\"T_f2f51_row18_col0\" class=\"data row18 col0\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row18_col1\" class=\"data row18 col1\" >0.987185</td>\n",
       "      <td id=\"T_f2f51_row18_col2\" class=\"data row18 col2\" >0.995838</td>\n",
       "      <td id=\"T_f2f51_row18_col3\" class=\"data row18 col3\" >1.000000</td>\n",
       "      <td id=\"T_f2f51_row18_col4\" class=\"data row18 col4\" >0.998400</td>\n",
       "      <td id=\"T_f2f51_row18_col5\" class=\"data row18 col5\" >0.544185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x76d8d6d3f190>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as LaTeX table\n",
    "METRIC = \"auc\" if TASK == \"classification\" else \"rmse\"\n",
    "\n",
    "scores_auc = scores[scores[\"metric\"] == METRIC]\n",
    "scores_auc_mean = scores_auc.groupby([\"embedding\", \"task\"])[\"score\"].mean()\n",
    "scores_auc_mean_pivot = scores_auc_mean.unstack()\n",
    "scores_auc_mean_pivot = scores_auc_mean_pivot.reindex(EMBEDDINGS)\n",
    "\n",
    "# Color each row based on the max score (if classification) or min score (if regression)\n",
    "if TASK == \"classification\":\n",
    "    scores_auc_mean_pivot_fancy = scores_auc_mean_pivot.T.style.apply(\n",
    "        lambda x: [\"background-color: darkgreen\" if x.max() == x.values[i] else \"\" for i in range(len(x))],\n",
    "        axis=1,\n",
    "    ).apply(\n",
    "        lambda x: [\"background-color: green\" if x.iloc[i] == x.nlargest(2).iloc[-1] and x.iloc[i] != x.max() else \"\" for i in range(len(x))],\n",
    "        axis=1,\n",
    "    )\n",
    "else:\n",
    "    scores_auc_mean_pivot_fancy = scores_auc_mean_pivot.T.style.apply(\n",
    "        lambda x: [\"background-color: darkgreen\" if x.min() == x.values[i] else \"\" for i in range(len(x))],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "scores_auc_mean_pivot_fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{rrccccccc}\\n\\\\toprule\\n& & & \\\\multicolumn{5}{c}{Embedding} \\\\\\\\\\nDataset& Task& \\\\#Samples& Raw& Random &  PCA$_{128}$& $\\\\mathcal{H}_{128}$& $\\\\mathcal{E}_{128}$& DNABERT-S\\\\\\\\\\n\\\\midrule\\n\\\\multirow{4}{*}{cho}\\n& control-ct-cecal & 17 & \\\\textbf{1.000} & 0.350 & 0.900 & 0.850 & 0.875 & \\\\textbf{1.000} \\\\\\\\\\n& control-ct-fecal & 18 & \\\\textbf{1.000} & 0.200 & \\\\textbf{1.000} & \\\\textbf{1.000} & \\\\textbf{1.000} & \\\\textbf{1.000} \\\\\\\\\\n& penicillin-vancomycin-cecal & 20 & \\\\textbf{1.000} & 0.325 & 0.800 & 0.900 & 0.900 & 0.950 \\\\\\\\\\n& penicillin-vancomycin-fecal & 19 & \\\\textbf{0.950} & 0.900 & 0.450 & 0.800 & 0.750 & 0.900 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{2}{*}{gevers}\\n& ileum & 140 & \\\\textbf{0.821} & 0.422 & 0.771 & 0.769 & 0.770 & 0.749 \\\\\\\\\\n& rectum & 160 & \\\\textbf{0.848} & 0.528 & 0.795 & 0.760 & 0.787 & 0.738 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{4}{*}{hmp}\\n& gastro-oral & 2070 & \\\\textbf{1.000} & 0.465 & \\\\textbf{1.000} & \\\\textbf{1.000} & \\\\textbf{1.000} & 1.000 \\\\\\\\\\n& sex & 180 & \\\\textbf{0.657} & 0.487 & 0.597 & 0.650 & 0.595 & 0.577 \\\\\\\\\\n& stool-tongue-paired & 404 & \\\\textbf{1.000} & 0.523 & \\\\textbf{1.000} & \\\\textbf{1.000} & \\\\textbf{1.000} & \\\\textbf{1.000} \\\\\\\\\\n& sub-supragingivalplaque-paired & 408 & \\\\textbf{0.838} & 0.496 & 0.759 & 0.745 & 0.762 & 0.761 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{3}{*}{ravel}\\n& black-hispanic & 199 & \\\\textbf{0.642} & 0.470 & 0.522 & 0.535 & 0.547 & 0.524 \\\\\\\\\\n& nugent-category & 342 & 0.981 & 0.479 & 0.972 & \\\\textbf{0.981} & 0.981 & 0.976 \\\\\\\\\\n& white-black & 200 & \\\\textbf{0.666} & 0.566 & 0.603 & 0.628 & 0.641 & 0.636 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{2}{*}{sokol}\\n& healthy-cd & 74 & \\\\textbf{0.866} & 0.406 & 0.616 & 0.708 & 0.656 & 0.673 \\\\\\\\\\n& healthy-uc & 59 & \\\\textbf{0.870} & 0.631 & 0.632 & 0.704 & 0.681 & 0.703 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{1}{*}{turnbaugh}\\n& obese-lean-all & 142 & \\\\textbf{0.786} & 0.630 & 0.622 & 0.620 & 0.620 & 0.631 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{3}{*}{yatsunenko}\\n& malawi-venezuela & 54 & \\\\textbf{1.000} & 0.344 & 0.874 & 0.779 & 0.800 & 0.867 \\\\\\\\\\n& sex & 129 & \\\\textbf{0.611} & 0.412 & 0.427 & 0.525 & 0.455 & 0.455 \\\\\\\\\\n& usa-malawi & 150 & \\\\textbf{1.000} & 0.544 & \\\\textbf{1.000} & 0.987 & 0.996 & 0.998 \\\\\\\\\\n\\\\midrule\\n\\\\multicolumn{3}{r}{Averages:} & \\\\textbf{0.870}& 0.483& 0.755& 0.786& 0.780& 0.797\\\\\\\\\\n\\\\multicolumn{3}{r}{Top scores:} & \\\\textbf{18}& 0& 4& 4& 3& 3\\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_nice_latex_table(input_data, output_file=None, include_raw=True, find_maximum=True):\n",
    "    # Parse the input data if it's a string\n",
    "    if isinstance(input_data, str):\n",
    "        # Extract data from the LaTeX table string\n",
    "        lines = input_data.strip().split(\"\\n\")\n",
    "\n",
    "        # Find header line and data lines\n",
    "        header_line = None\n",
    "        data_lines = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"embedding & raw\" in line:\n",
    "                header_line = i\n",
    "            if header_line is not None and i > header_line + 2 and \"\\\\bottomrule\" not in line:\n",
    "                data_lines.append(line)\n",
    "\n",
    "        # Extract column names\n",
    "        header = lines[header_line].strip().replace(\"\\\\\\\\\", \"\")\n",
    "        columns = [col.strip() for col in header.split(\"&\")]\n",
    "\n",
    "        # Extract data\n",
    "        data = []\n",
    "        for line in data_lines:\n",
    "            if \"\\\\bottomrule\" in line or \"\\\\midrule\" in line:\n",
    "                continue\n",
    "            row_data = line.strip().replace(\"\\\\\\\\\", \"\").split(\"&\")\n",
    "            row_data = [val.strip() for val in row_data]\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "    else:\n",
    "        # Assume input is already a DataFrame\n",
    "        df = input_data.copy()\n",
    "\n",
    "        # If the index contains the task names, reset the index to make it a column\n",
    "        if df.index.name == \"task\" or (isinstance(df.index, pd.MultiIndex) and \"task\" in df.index.names):\n",
    "            df = df.reset_index()\n",
    "\n",
    "    # Check if we have a 'task' column, if not try to see if it's the first column\n",
    "    if \"task\" not in df.columns and len(df.columns) > 0:\n",
    "        # Assume first column is the task column\n",
    "        df = df.rename(columns={df.columns[0]: \"task\"})\n",
    "\n",
    "    # Convert numeric columns to float\n",
    "    numeric_cols = [\"raw\", \"random\", \"PCA128\", \"H128\", \"E128\", \"dnabert-s\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float)\n",
    "\n",
    "    # Extract dataset name and task from the task column\n",
    "    df[\"dataset\"] = df[\"task\"].apply(lambda x: str(x).split(\"_\")[0] if \"_\" in str(x) else \"\")\n",
    "    df[\"task_name\"] = df[\"task\"].apply(lambda x: str(x).split(\"_\")[1] if \"_\" in str(x) else str(x))\n",
    "\n",
    "    # Count samples per task (dummy values for now, would be replaced with actual counts)\n",
    "    # In a real scenario, you might have this data available\n",
    "    sample_counts = {\n",
    "        # Classification datasets\n",
    "        \"cho_control-ct-cecal\": 17,\n",
    "        \"cho_control-ct-fecal\": 18,\n",
    "        \"cho_penicillin-vancomycin-cecal\": 20,\n",
    "        \"cho_penicillin-vancomycin-fecal\": 19,\n",
    "        \"gevers_ileum\": 140,\n",
    "        \"gevers_rectum\": 160,\n",
    "        \"hmp_gastro-oral\": 2070,\n",
    "        \"hmp_sex\": 180,\n",
    "        \"hmp_stool-tongue-paired\": 404,\n",
    "        \"hmp_sub-supragingivalplaque-paired\": 408,\n",
    "        \"ravel_black-hispanic\": 199,\n",
    "        \"ravel_nugent-category\": 342,\n",
    "        \"ravel_white-black\": 200,\n",
    "        \"sokol_healthy-cd\": 74,\n",
    "        \"sokol_healthy-uc\": 59,\n",
    "        \"turnbaugh_obese-lean-all\": 142,\n",
    "        \"yatsunenko_malawi-venezuela\": 54,\n",
    "        \"yatsunenko_sex\": 129,\n",
    "        \"yatsunenko_usa-malawi\": 150,\n",
    "        # Regression datasets\n",
    "        \"gevers_pcdai-ileum\": 67,\n",
    "        \"gevers_pcdai-rectum\": 51,\n",
    "        \"ravel_nugent-score\": 388,\n",
    "        \"ravel_ph\": 388,\n",
    "        \"yatsunenko_baby-age\": 49,\n",
    "    }\n",
    "\n",
    "    df[\"samples\"] = df[\"task\"].map(sample_counts)\n",
    "\n",
    "    # Determine which columns to consider for scoring\n",
    "    scoring_cols = numeric_cols if include_raw else [col for col in numeric_cols if col != \"raw\"]\n",
    "\n",
    "    # Count top scores for each method (including ties)\n",
    "    top_scores = {col: 0 for col in numeric_cols}\n",
    "\n",
    "    # For each row, find methods that have the max score (could be multiple in case of ties)\n",
    "    for idx, row in df.iterrows():\n",
    "        row_scores = {col: row[col] for col in scoring_cols if col in row}\n",
    "        if row_scores:\n",
    "            best_score = max(row_scores.values()) if find_maximum else min(row_scores.values())\n",
    "            for col in numeric_cols:\n",
    "                if (\n",
    "                    col in row_scores and abs(row_scores[col] - best_score) < 1e-6\n",
    "                ):  # Using small epsilon for float comparison\n",
    "                    top_scores[col] += 1\n",
    "\n",
    "    # Calculate averages for each method\n",
    "    averages = {col: df[col].mean() if col in df.columns else 0 for col in numeric_cols}\n",
    "\n",
    "    # For averages, determine best based on find_maximum setting\n",
    "    scoring_averages = {col: averages[col] for col in scoring_cols}\n",
    "    best_avg = (\n",
    "        max(scoring_averages.values()) if find_maximum else min(scoring_averages.values()) if scoring_averages else 0\n",
    "    )\n",
    "\n",
    "    # Start building the LaTeX table\n",
    "    latex_output = []\n",
    "    latex_output.append(\"\\\\begin{tabular}{rrccccccc}\")\n",
    "    latex_output.append(\"\\\\toprule\")\n",
    "    latex_output.append(\"& & & \\\\multicolumn{5}{c}{Embedding} \\\\\\\\\")\n",
    "    latex_output.append(\n",
    "        \"Dataset& Task& \\\\#Samples& Raw& Random &  PCA$_{128}$& $\\\\mathcal{H}_{128}$& $\\\\mathcal{E}_{128}$& DNABERT-S\\\\\\\\\"\n",
    "    )\n",
    "    latex_output.append(\"\\\\midrule\")\n",
    "\n",
    "    # Group by dataset\n",
    "    datasets = df[\"dataset\"].unique()\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        dataset_rows = df[df[\"dataset\"] == dataset]\n",
    "        n_rows = len(dataset_rows)\n",
    "\n",
    "        # Add multirow for dataset\n",
    "        if n_rows > 1:\n",
    "            latex_output.append(f\"\\\\multirow{{{n_rows}}}{{*}}{{{dataset}}}\")\n",
    "        else:\n",
    "            latex_output.append(f\"\\\\multirow{{1}}{{*}}{{{dataset}}}\")\n",
    "\n",
    "        # Add each task row\n",
    "        for j, (_, row) in enumerate(dataset_rows.iterrows()):\n",
    "            task_part = f\"& {row['task_name']} & {row['samples']} \"\n",
    "\n",
    "            # Only add the dataset name for the first row of the dataset\n",
    "            if j > 0:\n",
    "                task_part = \"& \" + task_part[2:]\n",
    "\n",
    "            # Add scores with bold for best score(s)\n",
    "            scores_part = \"\"\n",
    "            # Find max score for this row to handle ties\n",
    "            row_scores = [row[col] for col in scoring_cols if col in row]\n",
    "            if row_scores:\n",
    "                max_score = max(row_scores)\n",
    "                for col in numeric_cols:\n",
    "                    if col in row and abs(row[col] - max_score) < 1e-6:  # Using small epsilon for float comparison\n",
    "                        scores_part += f\"& \\\\textbf{{{row[col]:.3f}}} \"\n",
    "                    else:\n",
    "                        scores_part += f\"& {row[col] if col in row else 0:.3f} \"\n",
    "            else:\n",
    "                scores_part = \"& \" * len(numeric_cols)\n",
    "\n",
    "            latex_output.append(task_part + scores_part + \"\\\\\\\\\")\n",
    "\n",
    "        # Add midrule between datasets\n",
    "        if i < len(datasets) - 1:\n",
    "            latex_output.append(\"\\\\midrule\")\n",
    "\n",
    "    # Add average row\n",
    "    latex_output.append(\"\\\\midrule\")\n",
    "    average_row = \"\\\\multicolumn{3}{r}{Averages:} \"\n",
    "    for col in numeric_cols:\n",
    "        if col in scoring_cols and abs(averages[col] - best_avg) < 1e-6:\n",
    "            average_row += f\"& \\\\textbf{{{averages[col]:.3f}}}\"\n",
    "        else:\n",
    "            average_row += f\"& {averages[col]:.3f}\"\n",
    "    latex_output.append(average_row + \"\\\\\\\\\")\n",
    "\n",
    "    # Add top scores row\n",
    "    top_score_row = \"\\\\multicolumn{3}{r}{Top scores:} \"\n",
    "    scoring_top_scores = {col: top_scores[col] for col in scoring_cols}\n",
    "    max_top_score = max(scoring_top_scores.values()) if scoring_top_scores else 0\n",
    "    for col in numeric_cols:\n",
    "        if col in scoring_cols and top_scores[col] == max_top_score:\n",
    "            top_score_row += f\"& \\\\textbf{{{top_scores[col]}}}\"\n",
    "        else:\n",
    "            top_score_row += f\"& {top_scores[col]}\"\n",
    "    latex_output.append(top_score_row + \"\\\\\\\\\")\n",
    "\n",
    "    # Finish the table\n",
    "    latex_output.append(\"\\\\bottomrule\")\n",
    "    latex_output.append(\"\\\\end{tabular}\")\n",
    "\n",
    "    # Join all lines\n",
    "    latex_table = \"\\n\".join(latex_output)\n",
    "\n",
    "    # Write to file if output_file is provided\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "\n",
    "create_nice_latex_table(\n",
    "    scores_auc_mean_pivot.T[[\"raw\", \"random\", \"PCA128\", \"H128\", \"E128\", \"dnabert-s\"]],\n",
    "    # include_raw=False,\n",
    "    output_file=f\"../figures/benchmark_scores_sklearn_rf_None_{TASK}.tex\",\n",
    "    find_maximum=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
