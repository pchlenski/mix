{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "\n",
    "mlrepo = anndata.read_h5ad(\"../data/mlrepo6.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a869bcb8340940fdadbe42fe2c7077a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>embedding</th>\n",
       "      <th>fold</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ravel_nugent-score</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.737442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ravel_nugent-score</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.119231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ravel_nugent-score</td>\n",
       "      <td>raw</td>\n",
       "      <td>0</td>\n",
       "      <td>rmse</td>\n",
       "      <td>1.706244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ravel_nugent-score</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.725823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ravel_nugent-score</td>\n",
       "      <td>raw</td>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.212308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>yatsunenko_baby-age</td>\n",
       "      <td>random_mix</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.308550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>yatsunenko_baby-age</td>\n",
       "      <td>random_mix</td>\n",
       "      <td>3</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.341535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>yatsunenko_baby-age</td>\n",
       "      <td>random_mix</td>\n",
       "      <td>4</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.340589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>yatsunenko_baby-age</td>\n",
       "      <td>random_mix</td>\n",
       "      <td>4</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.287767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>yatsunenko_baby-age</td>\n",
       "      <td>random_mix</td>\n",
       "      <td>4</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.319403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    task   embedding  fold metric     score\n",
       "0     ravel_nugent-score         raw     0     r2  0.737442\n",
       "1     ravel_nugent-score         raw     0    mae  1.119231\n",
       "2     ravel_nugent-score         raw     0   rmse  1.706244\n",
       "3     ravel_nugent-score         raw     1     r2  0.725823\n",
       "4     ravel_nugent-score         raw     1    mae  1.212308\n",
       "..                   ...         ...   ...    ...       ...\n",
       "520  yatsunenko_baby-age  random_mix     3    mae  0.308550\n",
       "521  yatsunenko_baby-age  random_mix     3   rmse  0.341535\n",
       "522  yatsunenko_baby-age  random_mix     4     r2  0.340589\n",
       "523  yatsunenko_baby-age  random_mix     4    mae  0.287767\n",
       "524  yatsunenko_baby-age  random_mix     4   rmse  0.319403\n",
       "\n",
       "[525 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Configuration\n",
    "# TASK = \"classification\"  # or \"regression\"\n",
    "TASK = \"regression\"\n",
    "MODEL = RandomForestRegressor if TASK == \"regression\" else RandomForestClassifier\n",
    "FOLDS = 5\n",
    "\n",
    "# Dataset and embedding configuration\n",
    "DATASETS = mlrepo.obs.columns.drop(\"dataset\")\n",
    "REGRESSION_DATASETS = [\n",
    "    \"ravel_nugent-score\",\n",
    "    \"ravel_ph\",\n",
    "    \"gevers_pcdai-ileum\",\n",
    "    \"gevers_pcdai-rectum\",\n",
    "    \"yatsunenko_baby-age\",\n",
    "]\n",
    "CLASSIFICATION_DATASETS = [d for d in DATASETS if d not in REGRESSION_DATASETS]\n",
    "DATASETS_FINAL = REGRESSION_DATASETS if TASK == \"regression\" else CLASSIFICATION_DATASETS\n",
    "\n",
    "EMBEDDINGS = [\n",
    "    \"raw\",\n",
    "    # \"H2\",\n",
    "    # \"H4\",\n",
    "    # \"H8\",\n",
    "    # \"H16\",\n",
    "    # \"H32\",\n",
    "    # \"H64\",\n",
    "    \"H128\",\n",
    "    # \"E2\",\n",
    "    # \"E4\",\n",
    "    # \"E8\",\n",
    "    # \"E16\",\n",
    "    # \"E32\",\n",
    "    # \"E64\",\n",
    "    \"E128\",\n",
    "    \"PCA128\",\n",
    "    \"dnabert-s\",\n",
    "    \"random\",\n",
    "    \"random_mix\",\n",
    "]\n",
    "METRICS = [\"accuracy\", \"f1\", \"auc\"] if TASK == \"classification\" else [\"r2\", \"mae\", \"rmse\"]\n",
    "\n",
    "\n",
    "def get_embedding(mlrepo_filtered, embedding_name):\n",
    "    \"\"\"Get embedding data and product manifold\"\"\"\n",
    "    if embedding_name == \"raw\":\n",
    "        X = mlrepo_filtered.X\n",
    "    elif embedding_name == \"random\":\n",
    "        X = np.random.randn(mlrepo_filtered.X.shape[0], 128)\n",
    "    elif embedding_name == \"random_mix\":\n",
    "        X = mlrepo_filtered.X @ np.random.randn(mlrepo_filtered.n_vars, 128)\n",
    "    else:\n",
    "        X = mlrepo_filtered.obsm[embedding_name]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def calculate_score(y_true, y_pred, metric):\n",
    "    \"\"\"Calculate the specified evaluation metric\"\"\"\n",
    "    if metric in [\"accuracy\", \"f1\"]:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    elif metric == \"auc\":\n",
    "        y_pred = y_pred[:, 1]\n",
    "\n",
    "    if metric == \"accuracy\":\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif metric == \"f1\":\n",
    "        return f1_score(y_true, y_pred)\n",
    "    elif metric == \"auc\":\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    elif metric == \"r2\":\n",
    "        return r2_score(y_true, y_pred)\n",
    "    elif metric == \"mae\":\n",
    "        return mean_absolute_error(y_true, y_pred)\n",
    "    elif metric == \"rmse\":\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # elif metric == \"percent_rmse\":\n",
    "    # return (np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"raw_values\")) / y_true).mean()\n",
    "\n",
    "\n",
    "scores = pd.DataFrame(columns=[\"task\", \"embedding\", \"fold\", \"metric\", \"score\"])\n",
    "\n",
    "# Calculate total iterations and initialize progress bar\n",
    "total_iterations = len(DATASETS_FINAL) * len(EMBEDDINGS) * FOLDS * len(METRICS)\n",
    "my_tqdm = tqdm(total=total_iterations)\n",
    "\n",
    "for task in DATASETS_FINAL:\n",
    "    # Filter mlrepo; drop empty columns\n",
    "    mlrepo_filtered = mlrepo[mlrepo.obs[task].notna()]\n",
    "    mlrepo_filtered = mlrepo_filtered[:, (mlrepo_filtered.X > 0).sum(axis=0) > 0]\n",
    "\n",
    "    # Get target values\n",
    "    y = np.array(mlrepo_filtered.obs[task].values)\n",
    "    if TASK == \"classification\":\n",
    "        y = OrdinalEncoder().fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    else:\n",
    "        y = y.flatten()\n",
    "\n",
    "    # Set up cross-validation\n",
    "    if TASK == \"classification\":\n",
    "        kf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create folds once to ensure consistency\n",
    "    folds = list(kf.split(np.zeros(len(y)), y))\n",
    "\n",
    "    for embedding in EMBEDDINGS:\n",
    "        # Get embedding data\n",
    "        X = get_embedding(mlrepo_filtered, embedding)\n",
    "\n",
    "        for fold_idx, (train_index, test_index) in enumerate(folds):\n",
    "            # Convert data to tensors\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Train model\n",
    "            model = MODEL()\n",
    "            model.fit(X_train, y_train)\n",
    "            if TASK == \"classification\":\n",
    "                y_out = model.predict_proba(X_test)  # Need this for ROC-AUC calculations\n",
    "            else:\n",
    "                y_out = model.predict(X_test)\n",
    "\n",
    "            # Calculate and store scores for each metric\n",
    "            for metric in METRICS:\n",
    "                score = calculate_score(y_test, y_out, metric)\n",
    "                scores.loc[len(scores)] = [task, embedding, fold_idx, metric, score]\n",
    "\n",
    "                # Update progress bar\n",
    "                my_tqdm.update(1)\n",
    "                my_tqdm.set_postfix(task=task, embedding=embedding, fold=fold_idx, metric=metric, score=score)\n",
    "\n",
    "        # Save checkpoint after each embedding\n",
    "        task_scores = scores[scores[\"task\"] == task]\n",
    "\n",
    "my_tqdm.close()\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(f\"../results/benchmark_scores_sklearn_rf_None_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_356b8_row0_col3, #T_356b8_row1_col5, #T_356b8_row2_col0, #T_356b8_row3_col2, #T_356b8_row4_col3 {\n",
       "  background-color: darkgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_356b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >embedding</th>\n",
       "      <th id=\"T_356b8_level0_col0\" class=\"col_heading level0 col0\" >raw</th>\n",
       "      <th id=\"T_356b8_level0_col1\" class=\"col_heading level0 col1\" >H128</th>\n",
       "      <th id=\"T_356b8_level0_col2\" class=\"col_heading level0 col2\" >E128</th>\n",
       "      <th id=\"T_356b8_level0_col3\" class=\"col_heading level0 col3\" >PCA128</th>\n",
       "      <th id=\"T_356b8_level0_col4\" class=\"col_heading level0 col4\" >dnabert-s</th>\n",
       "      <th id=\"T_356b8_level0_col5\" class=\"col_heading level0 col5\" >random</th>\n",
       "      <th id=\"T_356b8_level0_col6\" class=\"col_heading level0 col6\" >random_mix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >task</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_356b8_level0_row0\" class=\"row_heading level0 row0\" >gevers_pcdai-ileum</th>\n",
       "      <td id=\"T_356b8_row0_col0\" class=\"data row0 col0\" >16.259076</td>\n",
       "      <td id=\"T_356b8_row0_col1\" class=\"data row0 col1\" >15.648570</td>\n",
       "      <td id=\"T_356b8_row0_col2\" class=\"data row0 col2\" >16.447425</td>\n",
       "      <td id=\"T_356b8_row0_col3\" class=\"data row0 col3\" >15.511502</td>\n",
       "      <td id=\"T_356b8_row0_col4\" class=\"data row0 col4\" >15.880750</td>\n",
       "      <td id=\"T_356b8_row0_col5\" class=\"data row0 col5\" >16.518823</td>\n",
       "      <td id=\"T_356b8_row0_col6\" class=\"data row0 col6\" >15.731620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_356b8_level0_row1\" class=\"row_heading level0 row1\" >gevers_pcdai-rectum</th>\n",
       "      <td id=\"T_356b8_row1_col0\" class=\"data row1 col0\" >17.474227</td>\n",
       "      <td id=\"T_356b8_row1_col1\" class=\"data row1 col1\" >17.346752</td>\n",
       "      <td id=\"T_356b8_row1_col2\" class=\"data row1 col2\" >18.047597</td>\n",
       "      <td id=\"T_356b8_row1_col3\" class=\"data row1 col3\" >15.803861</td>\n",
       "      <td id=\"T_356b8_row1_col4\" class=\"data row1 col4\" >17.338155</td>\n",
       "      <td id=\"T_356b8_row1_col5\" class=\"data row1 col5\" >13.999359</td>\n",
       "      <td id=\"T_356b8_row1_col6\" class=\"data row1 col6\" >16.565879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_356b8_level0_row2\" class=\"row_heading level0 row2\" >ravel_nugent-score</th>\n",
       "      <td id=\"T_356b8_row2_col0\" class=\"data row2 col0\" >1.700946</td>\n",
       "      <td id=\"T_356b8_row2_col1\" class=\"data row2 col1\" >1.780565</td>\n",
       "      <td id=\"T_356b8_row2_col2\" class=\"data row2 col2\" >1.799264</td>\n",
       "      <td id=\"T_356b8_row2_col3\" class=\"data row2 col3\" >1.765010</td>\n",
       "      <td id=\"T_356b8_row2_col4\" class=\"data row2 col4\" >1.837810</td>\n",
       "      <td id=\"T_356b8_row2_col5\" class=\"data row2 col5\" >3.608426</td>\n",
       "      <td id=\"T_356b8_row2_col6\" class=\"data row2 col6\" >1.833295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_356b8_level0_row3\" class=\"row_heading level0 row3\" >ravel_ph</th>\n",
       "      <td id=\"T_356b8_row3_col0\" class=\"data row3 col0\" >0.516080</td>\n",
       "      <td id=\"T_356b8_row3_col1\" class=\"data row3 col1\" >0.500351</td>\n",
       "      <td id=\"T_356b8_row3_col2\" class=\"data row3 col2\" >0.483967</td>\n",
       "      <td id=\"T_356b8_row3_col3\" class=\"data row3 col3\" >0.496704</td>\n",
       "      <td id=\"T_356b8_row3_col4\" class=\"data row3 col4\" >0.486776</td>\n",
       "      <td id=\"T_356b8_row3_col5\" class=\"data row3 col5\" >0.685133</td>\n",
       "      <td id=\"T_356b8_row3_col6\" class=\"data row3 col6\" >0.512432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_356b8_level0_row4\" class=\"row_heading level0 row4\" >yatsunenko_baby-age</th>\n",
       "      <td id=\"T_356b8_row4_col0\" class=\"data row4 col0\" >0.250692</td>\n",
       "      <td id=\"T_356b8_row4_col1\" class=\"data row4 col1\" >0.310933</td>\n",
       "      <td id=\"T_356b8_row4_col2\" class=\"data row4 col2\" >0.317515</td>\n",
       "      <td id=\"T_356b8_row4_col3\" class=\"data row4 col3\" >0.243360</td>\n",
       "      <td id=\"T_356b8_row4_col4\" class=\"data row4 col4\" >0.275145</td>\n",
       "      <td id=\"T_356b8_row4_col5\" class=\"data row4 col5\" >0.430145</td>\n",
       "      <td id=\"T_356b8_row4_col6\" class=\"data row4 col6\" >0.346892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x76d8cbd5b9d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as LaTeX table\n",
    "METRIC = \"auc\" if TASK == \"classification\" else \"rmse\"\n",
    "\n",
    "scores_auc = scores[scores[\"metric\"] == METRIC]\n",
    "scores_auc_mean = scores_auc.groupby([\"embedding\", \"task\"])[\"score\"].mean()\n",
    "scores_auc_mean_pivot = scores_auc_mean.unstack()\n",
    "scores_auc_mean_pivot = scores_auc_mean_pivot.reindex(EMBEDDINGS)\n",
    "\n",
    "# Color each row based on the max score (if classification) or min score (if regression)\n",
    "if TASK == \"classification\":\n",
    "    scores_auc_mean_pivot_fancy = scores_auc_mean_pivot.T.style.apply(\n",
    "        lambda x: [\"background-color: darkgreen\" if x.max() == x.values[i] else \"\" for i in range(len(x))],\n",
    "        axis=1,\n",
    "    ).apply(\n",
    "        lambda x: [\n",
    "            \"background-color: green\" if x.iloc[i] == x.nlargest(2).iloc[-1] and x.iloc[i] != x.max() else \"\"\n",
    "            for i in range(len(x))\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "else:\n",
    "    scores_auc_mean_pivot_fancy = scores_auc_mean_pivot.T.style.apply(\n",
    "        lambda x: [\"background-color: darkgreen\" if x.min() == x.values[i] else \"\" for i in range(len(x))],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "scores_auc_mean_pivot_fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{rrcccccccc}\\n\\\\toprule\\n& & \\\\multicolumn{7}{c}{Embedding} \\\\\\\\\\nDataset& Task& \\\\#Samples& Raw& Random & Random Mix &  PCA$_{128}$& $\\\\mathcal{H}_{128}$& $\\\\mathcal{E}_{128}$& DNABERT-S\\\\\\\\\\n\\\\midrule\\n\\\\multirow{2}{*}{gevers}\\n& pcdai-ileum & 67 & 16.26 & \\\\textbf{16.52} & 15.73 & 15.51 & 15.65 & 16.45 & 15.88 \\\\\\\\\\n& pcdai-rectum & 51 & 17.47 & 14.00 & 16.57 & 15.80 & 17.35 & \\\\textbf{18.05} & 17.34 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{2}{*}{ravel}\\n& nugent-score & 388 & 1.70 & \\\\textbf{3.61} & 1.83 & 1.77 & 1.78 & 1.80 & 1.84 \\\\\\\\\\n& ph & 388 & 0.52 & \\\\textbf{0.69} & 0.51 & 0.50 & 0.50 & 0.48 & 0.49 \\\\\\\\\\n\\\\midrule\\n\\\\multirow{1}{*}{yatsunenko}\\n& baby-age & 49 & 0.25 & \\\\textbf{0.43} & 0.35 & 0.24 & 0.31 & 0.32 & 0.28 \\\\\\\\\\n\\\\midrule\\n\\\\multicolumn{3}{r}{Averages:} & 7.24& 7.05& 7.00& 6.76& 7.12& \\\\textbf{7.42}& 7.16\\\\\\\\\\n\\\\multicolumn{3}{r}{Top scores:} & 0& \\\\textbf{4}& 0& 0& 0& 1& 0\\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_nice_latex_table(input_data, output_file=None, include_raw=True, find_maximum=True):\n",
    "    # Parse the input data if it's a string\n",
    "    if isinstance(input_data, str):\n",
    "        # Extract data from the LaTeX table string\n",
    "        lines = input_data.strip().split(\"\\n\")\n",
    "\n",
    "        # Find header line and data lines\n",
    "        header_line = None\n",
    "        data_lines = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"embedding & raw\" in line:\n",
    "                header_line = i\n",
    "            if header_line is not None and i > header_line + 2 and \"\\\\bottomrule\" not in line:\n",
    "                data_lines.append(line)\n",
    "\n",
    "        # Extract column names\n",
    "        header = lines[header_line].strip().replace(\"\\\\\\\\\", \"\")\n",
    "        columns = [col.strip() for col in header.split(\"&\")]\n",
    "\n",
    "        # Extract data\n",
    "        data = []\n",
    "        for line in data_lines:\n",
    "            if \"\\\\bottomrule\" in line or \"\\\\midrule\" in line:\n",
    "                continue\n",
    "            row_data = line.strip().replace(\"\\\\\\\\\", \"\").split(\"&\")\n",
    "            row_data = [val.strip() for val in row_data]\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "    else:\n",
    "        # Assume input is already a DataFrame\n",
    "        df = input_data.copy()\n",
    "\n",
    "        # If the index contains the task names, reset the index to make it a column\n",
    "        if df.index.name == \"task\" or (isinstance(df.index, pd.MultiIndex) and \"task\" in df.index.names):\n",
    "            df = df.reset_index()\n",
    "\n",
    "    # Check if we have a 'task' column, if not try to see if it's the first column\n",
    "    if \"task\" not in df.columns and len(df.columns) > 0:\n",
    "        # Assume first column is the task column\n",
    "        df = df.rename(columns={df.columns[0]: \"task\"})\n",
    "\n",
    "    # Convert numeric columns to float\n",
    "    numeric_cols = [\"raw\", \"random\", \"random_mix\", \"PCA128\", \"H128\", \"E128\", \"dnabert-s\"]\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float)\n",
    "\n",
    "    # Extract dataset name and task from the task column\n",
    "    df[\"dataset\"] = df[\"task\"].apply(lambda x: str(x).split(\"_\")[0] if \"_\" in str(x) else \"\")\n",
    "    df[\"task_name\"] = df[\"task\"].apply(lambda x: str(x).split(\"_\")[1] if \"_\" in str(x) else str(x))\n",
    "\n",
    "    # Count samples per task (dummy values for now, would be replaced with actual counts)\n",
    "    # In a real scenario, you might have this data available\n",
    "    sample_counts = {\n",
    "        # Classification datasets\n",
    "        \"cho_control-ct-cecal\": 17,\n",
    "        \"cho_control-ct-fecal\": 18,\n",
    "        \"cho_penicillin-vancomycin-cecal\": 20,\n",
    "        \"cho_penicillin-vancomycin-fecal\": 19,\n",
    "        \"gevers_ileum\": 140,\n",
    "        \"gevers_rectum\": 160,\n",
    "        \"hmp_gastro-oral\": 2070,\n",
    "        \"hmp_sex\": 180,\n",
    "        \"hmp_stool-tongue-paired\": 404,\n",
    "        \"hmp_sub-supragingivalplaque-paired\": 408,\n",
    "        \"ravel_black-hispanic\": 199,\n",
    "        \"ravel_nugent-category\": 342,\n",
    "        \"ravel_white-black\": 200,\n",
    "        \"sokol_healthy-cd\": 74,\n",
    "        \"sokol_healthy-uc\": 59,\n",
    "        \"turnbaugh_obese-lean-all\": 142,\n",
    "        \"yatsunenko_malawi-venezuela\": 54,\n",
    "        \"yatsunenko_sex\": 129,\n",
    "        \"yatsunenko_usa-malawi\": 150,\n",
    "        # Regression datasets\n",
    "        \"gevers_pcdai-ileum\": 67,\n",
    "        \"gevers_pcdai-rectum\": 51,\n",
    "        \"ravel_nugent-score\": 388,\n",
    "        \"ravel_ph\": 388,\n",
    "        \"yatsunenko_baby-age\": 49,\n",
    "    }\n",
    "\n",
    "    df[\"samples\"] = df[\"task\"].map(sample_counts)\n",
    "\n",
    "    # Determine which columns to consider for scoring\n",
    "    scoring_cols = numeric_cols if include_raw else [col for col in numeric_cols if col != \"raw\"]\n",
    "\n",
    "    # Count top scores for each method (including ties)\n",
    "    top_scores = {col: 0 for col in numeric_cols}\n",
    "\n",
    "    # For each row, find methods that have the max score (could be multiple in case of ties)\n",
    "    for idx, row in df.iterrows():\n",
    "        row_scores = {col: row[col] for col in scoring_cols if col in row}\n",
    "        if row_scores:\n",
    "            best_score = max(row_scores.values()) if find_maximum else min(row_scores.values())\n",
    "            for col in numeric_cols:\n",
    "                if (\n",
    "                    col in row_scores and abs(row_scores[col] - best_score) < 1e-6\n",
    "                ):  # Using small epsilon for float comparison\n",
    "                    top_scores[col] += 1\n",
    "\n",
    "    # Calculate averages for each method\n",
    "    averages = {col: df[col].mean() if col in df.columns else 0 for col in numeric_cols}\n",
    "\n",
    "    # For averages, determine best based on find_maximum setting\n",
    "    scoring_averages = {col: averages[col] for col in scoring_cols}\n",
    "    best_avg = (\n",
    "        max(scoring_averages.values()) if find_maximum else min(scoring_averages.values()) if scoring_averages else 0\n",
    "    )\n",
    "\n",
    "    # Start building the LaTeX table\n",
    "    latex_output = []\n",
    "    latex_output.append(\"\\\\begin{tabular}{rrcccccccc}\")\n",
    "    latex_output.append(\"\\\\toprule\")\n",
    "    latex_output.append(\"& & \\\\multicolumn{7}{c}{Embedding} \\\\\\\\\")\n",
    "    latex_output.append(\n",
    "        \"Dataset& Task& \\\\#Samples& Raw& Random & Random Mix &  PCA$_{128}$& $\\\\mathcal{H}_{128}$& $\\\\mathcal{E}_{128}$& DNABERT-S\\\\\\\\\"\n",
    "    )\n",
    "    latex_output.append(\"\\\\midrule\")\n",
    "\n",
    "    # Group by dataset\n",
    "    datasets = df[\"dataset\"].unique()\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        dataset_rows = df[df[\"dataset\"] == dataset]\n",
    "        n_rows = len(dataset_rows)\n",
    "\n",
    "        # Add multirow for dataset\n",
    "        if n_rows > 1:\n",
    "            latex_output.append(f\"\\\\multirow{{{n_rows}}}{{*}}{{{dataset}}}\")\n",
    "        else:\n",
    "            latex_output.append(f\"\\\\multirow{{1}}{{*}}{{{dataset}}}\")\n",
    "\n",
    "        # Add each task row\n",
    "        for j, (_, row) in enumerate(dataset_rows.iterrows()):\n",
    "            task_part = f\"& {row['task_name']} & {row['samples']} \"\n",
    "\n",
    "            # Only add the dataset name for the first row of the dataset\n",
    "            if j > 0:\n",
    "                task_part = \"& \" + task_part[2:]\n",
    "\n",
    "            # Add scores with bold for best score(s)\n",
    "            scores_part = \"\"\n",
    "            # Find max score for this row to handle ties\n",
    "            row_scores = [row[col] for col in scoring_cols if col in row]\n",
    "            if row_scores:\n",
    "                max_score = max(row_scores)\n",
    "                for col in numeric_cols:\n",
    "                    if col in row and abs(row[col] - max_score) < 1e-2:  # Using small epsilon for float comparison\n",
    "                        scores_part += f\"& \\\\textbf{{{row[col]:.2f}}} \"\n",
    "                    else:\n",
    "                        scores_part += f\"& {row[col] if col in row else 0:.2f} \"\n",
    "            else:\n",
    "                scores_part = \"& \" * len(numeric_cols)\n",
    "\n",
    "            latex_output.append(task_part + scores_part + \"\\\\\\\\\")\n",
    "\n",
    "        # Add midrule between datasets\n",
    "        if i < len(datasets) - 1:\n",
    "            latex_output.append(\"\\\\midrule\")\n",
    "\n",
    "    # Add average row\n",
    "    latex_output.append(\"\\\\midrule\")\n",
    "    average_row = \"\\\\multicolumn{3}{r}{Averages:} \"\n",
    "    for col in numeric_cols:\n",
    "        if col in scoring_cols and abs(averages[col] - best_avg) < 1e-6:\n",
    "            average_row += f\"& \\\\textbf{{{averages[col]:.2f}}}\"\n",
    "        else:\n",
    "            average_row += f\"& {averages[col]:.2f}\"\n",
    "    latex_output.append(average_row + \"\\\\\\\\\")\n",
    "\n",
    "    # Add top scores row\n",
    "    top_score_row = \"\\\\multicolumn{3}{r}{Top scores:} \"\n",
    "    scoring_top_scores = {col: top_scores[col] for col in scoring_cols}\n",
    "    max_top_score = max(scoring_top_scores.values()) if scoring_top_scores else 0\n",
    "    for col in numeric_cols:\n",
    "        if col in scoring_cols and top_scores[col] == max_top_score:\n",
    "            top_score_row += f\"& \\\\textbf{{{top_scores[col]}}}\"\n",
    "        else:\n",
    "            top_score_row += f\"& {top_scores[col]}\"\n",
    "    latex_output.append(top_score_row + \"\\\\\\\\\")\n",
    "\n",
    "    # Finish the table\n",
    "    latex_output.append(\"\\\\bottomrule\")\n",
    "    latex_output.append(\"\\\\end{tabular}\")\n",
    "\n",
    "    # Join all lines\n",
    "    latex_table = \"\\n\".join(latex_output)\n",
    "\n",
    "    # Write to file if output_file is provided\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "\n",
    "create_nice_latex_table(\n",
    "    scores_auc_mean_pivot.T[[\"raw\", \"random\", \"random_mix\", \"PCA128\", \"H128\", \"E128\", \"dnabert-s\"]],\n",
    "    # include_raw=False,\n",
    "    output_file=f\"../figures/benchmark_scores_sklearn_rf_None_{TASK}.tex\",\n",
    "    find_maximum=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
